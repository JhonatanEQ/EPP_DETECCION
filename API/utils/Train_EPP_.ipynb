{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8858d7",
   "metadata": {},
   "source": [
    "# üéØ Entrenamiento de Modelo YOLO para Detecci√≥n de EPP\n",
    "\n",
    "## üìã Preparaci√≥n Local (ANTES de usar Colab)\n",
    "\n",
    "### Opci√≥n 1: Dataset Ya Organizado (Recomendado)\n",
    "```powershell\n",
    "# En tu PC (PowerShell)\n",
    "cd API\\models\n",
    "python organize_dataset_for_yolo.py\n",
    "Compress-Archive -Path \"EPP_dataset\" -DestinationPath \"EPP_dataset.zip\"\n",
    "```\n",
    "**Resultado**: `EPP_dataset.zip` (~3-5 GB)\n",
    "\n",
    "### Opci√≥n 2: Dataset por Carpetas\n",
    "```powershell\n",
    "# Si ya generaste el dataset augmentado\n",
    "Compress-Archive -Path \"imagenes_epp_augmented\" -DestinationPath \"imagenes_epp_augmented.zip\"\n",
    "```\n",
    "**Resultado**: `imagenes_epp_augmented.zip` (~3-5 GB)\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Pasos en Google Colab\n",
    "\n",
    "1. **Activar GPU**: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
    "2. **Ejecutar celdas** en orden (1Ô∏è‚É£ ‚Üí 1Ô∏è‚É£1Ô∏è‚É£)\n",
    "3. **Subir ZIP** cuando se solicite (celda 3Ô∏è‚É£)\n",
    "4. **Esperar** ~2-3 horas para entrenamiento completo\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Clases EPP (8)\n",
    "\n",
    "0. **barbijo** - Mascarilla/Tapabocas\n",
    "1. **botas** - Calzado de seguridad  \n",
    "2. **camisa** - Camisa de trabajo\n",
    "3. **casco** - Casco de seguridad\n",
    "4. **chaleco** - Chaleco reflectivo\n",
    "5. **guantes** - Guantes de protecci√≥n\n",
    "6. **lentes** - Gafas de seguridad\n",
    "7. **pantalon** - Pantal√≥n de trabajo\n",
    "\n",
    "**Nota**: `epp_completo` se calcula program√°ticamente (no se entrena)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Consejos\n",
    "\n",
    "- **GPU requerida**: El entrenamiento es muy lento en CPU\n",
    "- **Tiempo estimado**: 2-3 horas con GPU T4 (50 √©pocas)\n",
    "- **Dataset**: ~14,000 im√°genes (8 clases)\n",
    "- **Resultado**: Modelo `ppe_best.pt` para descargar\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Verificar GPU disponible\n",
    "import torch\n",
    "print(f\"PyTorch versi√≥n: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPU no detectada. Activa GPU en: Runtime ‚Üí Change runtime type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Instalar Ultralytics (YOLOv8)\n",
    "!pip install ultralytics -q\n",
    "print(\"‚úÖ Ultralytics instalado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Montar Google Drive y copiar dataset\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Montar Drive\n",
    "print(\"üìÅ Montando Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n‚úÖ Google Drive montado exitosamente\")\n",
    "print(\"\\nüîç Buscando EPP_dataset.zip en tu Drive...\\n\")\n",
    "\n",
    "# Posibles ubicaciones del archivo\n",
    "drive_paths = [\n",
    "    '/content/drive/MyDrive/EPP_dataset.zip',\n",
    "    '/content/drive/My Drive/EPP_dataset.zip',\n",
    "]\n",
    "\n",
    "zip_found = False\n",
    "source_path = None\n",
    "\n",
    "for path in drive_paths:\n",
    "    if os.path.exists(path):\n",
    "        source_path = path\n",
    "        file_size = os.path.getsize(path) / (1024**3)  # GB\n",
    "        print(f\"‚úÖ Encontrado: {path}\")\n",
    "        print(f\"   Tama√±o: {file_size:.2f} GB\")\n",
    "        zip_found = True\n",
    "        break\n",
    "\n",
    "if zip_found:\n",
    "    print(f\"\\nüì¶ Copiando desde Drive a Colab (puede tardar 2-5 minutos)...\")\n",
    "    !cp \"{source_path}\" /content/EPP_dataset.zip\n",
    "    \n",
    "    # Verificar copia\n",
    "    if os.path.exists('/content/EPP_dataset.zip'):\n",
    "        print(\"‚úÖ Archivo copiado exitosamente a /content/\")\n",
    "        print(f\"   Tama√±o: {os.path.getsize('/content/EPP_dataset.zip') / (1024**3):.2f} GB\")\n",
    "    else:\n",
    "        print(\"‚ùå Error al copiar el archivo\")\n",
    "else:\n",
    "    print(\"‚ùå No se encontr√≥ EPP_dataset.zip en tu Google Drive\")\n",
    "    print(\"\\nüìã Instrucciones:\")\n",
    "    print(\"   1. Ve a https://drive.google.com\")\n",
    "    print(\"   2. Sube EPP_dataset.zip a 'Mi unidad' (ra√≠z)\")\n",
    "    print(\"   3. Espera a que termine la subida\")\n",
    "    print(\"   4. Vuelve a ejecutar esta celda\")\n",
    "    print(\"\\nüîç Listando archivos en tu Drive:\")\n",
    "    !ls -lh \"/content/drive/MyDrive/\" | head -20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c69c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ Extraer dataset\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Detectar qu√© archivo ZIP existe\n",
    "if os.path.exists('EPP_dataset.zip'):\n",
    "    zip_file = 'EPP_dataset.zip'\n",
    "    extract_to = '.'\n",
    "    print(\"üì¶ Extrayendo EPP_dataset.zip (ya organizado para YOLO)...\")\n",
    "elif os.path.exists('imagenes_epp_augmented.zip'):\n",
    "    zip_file = 'imagenes_epp_augmented.zip'\n",
    "    extract_to = '.'\n",
    "    print(\"üì¶ Extrayendo imagenes_epp_augmented.zip...\")\n",
    "else:\n",
    "    print(\"‚ùå No se encontr√≥ ning√∫n archivo ZIP\")\n",
    "    print(\"   Sube EPP_dataset.zip o imagenes_epp_augmented.zip\")\n",
    "    raise FileNotFoundError(\"No se encontr√≥ archivo ZIP del dataset\")\n",
    "\n",
    "# Extraer\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "print(\"‚úÖ Dataset extra√≠do\")\n",
    "\n",
    "# Verificar estructura\n",
    "print(\"\\nüìÅ Archivos extra√≠dos:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f6169",
   "metadata": {},
   "source": [
    "## üìÅ Preparar Estructura del Dataset\n",
    "\n",
    "Despu√©s de extraer el dataset, debes organizarlo en esta estructura:\n",
    "\n",
    "```\n",
    "EPP_dataset/\n",
    "‚îú‚îÄ‚îÄ data.yaml\n",
    "‚îî‚îÄ‚îÄ images/\n",
    "    ‚îú‚îÄ‚îÄ train/         # 70% de las im√°genes\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ barbijo_001.jpg\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ botas_002.jpg\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "    ‚îú‚îÄ‚îÄ val/           # 15% de las im√°genes\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "    ‚îî‚îÄ‚îÄ test/          # 15% de las im√°genes (opcional)\n",
    "        ‚îî‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "**Nota:** Si usaste `generate_augmented_dataset.py`, tus im√°genes est√°n en carpetas por clase. Necesitas reorganizarlas en la estructura de YOLO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e0581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£.1 Organizar dataset (SOLO si subiste imagenes_epp_augmented.zip)\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "def organize_dataset_for_yolo(source_dir='imagenes_epp_augmented', output_dir='EPP_dataset'):\n",
    "    \"\"\"\n",
    "    Organiza im√°genes de carpetas por clase a estructura YOLO.\n",
    "    \n",
    "    Divide en:\n",
    "    - 70% entrenamiento (train)\n",
    "    - 15% validaci√≥n (val)\n",
    "    - 15% prueba (test)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Clases (SIN epp_completo - se calcula program√°ticamente)\n",
    "    classes = ['barbijo', 'botas', 'camisa', 'casco', 'chaleco', \n",
    "               'guantes', 'lentes', 'pantalon']\n",
    "    \n",
    "    # Crear estructura\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        os.makedirs(f'{output_dir}/images/{split}', exist_ok=True)\n",
    "        os.makedirs(f'{output_dir}/labels/{split}', exist_ok=True)\n",
    "    \n",
    "    print(\"üìÅ Organizando dataset para YOLO (8 clases)...\\n\")\n",
    "    \n",
    "    total_images = 0\n",
    "    stats = {'train': 0, 'val': 0, 'test': 0}\n",
    "    \n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_dir = Path(source_dir) / class_name\n",
    "        \n",
    "        if not class_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è  Carpeta no encontrada: {class_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener todas las im√°genes\n",
    "        images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png'))\n",
    "        random.shuffle(images)\n",
    "        \n",
    "        # Calcular divisiones\n",
    "        n_images = len(images)\n",
    "        n_train = int(n_images * 0.70)\n",
    "        n_val = int(n_images * 0.15)\n",
    "        \n",
    "        train_imgs = images[:n_train]\n",
    "        val_imgs = images[n_train:n_train + n_val]\n",
    "        test_imgs = images[n_train + n_val:]\n",
    "        \n",
    "        # Copiar im√°genes y crear etiquetas\n",
    "        for split, imgs in [('train', train_imgs), ('val', val_imgs), ('test', test_imgs)]:\n",
    "            for img_path in imgs:\n",
    "                # Copiar imagen\n",
    "                dest_img = f\"{output_dir}/images/{split}/{img_path.name}\"\n",
    "                shutil.copy2(img_path, dest_img)\n",
    "                \n",
    "                # Crear archivo de etiqueta\n",
    "                # Para clasificaci√≥n de imagen completa:\n",
    "                label_path = f\"{output_dir}/labels/{split}/{img_path.stem}.txt\"\n",
    "                with open(label_path, 'w') as f:\n",
    "                    # Formato YOLO: class_id center_x center_y width height\n",
    "                    # Imagen completa = 0.5 0.5 1.0 1.0\n",
    "                    f.write(f\"{class_idx} 0.5 0.5 1.0 1.0\\n\")\n",
    "                \n",
    "                stats[split] += 1\n",
    "        \n",
    "        total_images += n_images\n",
    "        print(f\"‚úì {class_name:15s}: {n_train:4d} train + {n_val:4d} val + {len(test_imgs):4d} test = {n_images:4d} total\")\n",
    "    \n",
    "    print(f\"\\nüìä Resumen:\")\n",
    "    print(f\"  ‚Ä¢ Train:      {stats['train']:6d} im√°genes\")\n",
    "    print(f\"  ‚Ä¢ Validation: {stats['val']:6d} im√°genes\")\n",
    "    print(f\"  ‚Ä¢ Test:       {stats['test']:6d} im√°genes\")\n",
    "    print(f\"  ‚Ä¢ TOTAL:      {total_images:6d} im√°genes\")\n",
    "    print(f\"  ‚Ä¢ Clases:     {len(classes)} (sin epp_completo)\")\n",
    "    print(f\"\\n‚úÖ Dataset organizado en: {output_dir}/\")\n",
    "\n",
    "# Verificar si necesitamos organizar\n",
    "if os.path.exists('imagenes_epp_augmented'):\n",
    "    print(\"üîç Detectado: imagenes_epp_augmented/\")\n",
    "    print(\"   Organizando para YOLO (8 clases)...\\n\")\n",
    "    organize_dataset_for_yolo('imagenes_epp_augmented', 'EPP_dataset')\n",
    "elif os.path.exists('EPP_dataset/data.yaml'):\n",
    "    print(\"‚úÖ Dataset ya est√° organizado para YOLO\")\n",
    "    print(\"   Puedes continuar con el siguiente paso\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No se encontr√≥ el dataset\")\n",
    "    print(\"   Verifica que subiste el archivo ZIP correcto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9528b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5Ô∏è‚É£ Verificar data.yaml\n",
    "!cat EPP_dataset/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4daf915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6Ô∏è‚É£ Configurar data.yaml con 8 clases EPP (sin epp_completo)\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "# Configuraci√≥n del dataset\n",
    "data_config = {\n",
    "    'path': '/content/EPP_dataset',  # Ruta base del dataset\n",
    "    'train': 'images/train',          # Carpeta de entrenamiento\n",
    "    'val': 'images/val',              # Carpeta de validaci√≥n\n",
    "    'test': 'images/test',            # Carpeta de prueba (opcional)\n",
    "    \n",
    "    'nc': 8,  # N√∫mero de clases (sin epp_completo)\n",
    "    'names': [\n",
    "        'barbijo',      # 0\n",
    "        'botas',        # 1\n",
    "        'camisa',       # 2\n",
    "        'casco',        # 3\n",
    "        'chaleco',      # 4\n",
    "        'guantes',      # 5\n",
    "        'lentes',       # 6\n",
    "        'pantalon'      # 7\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Guardar configuraci√≥n\n",
    "with open('EPP_dataset/data.yaml', 'w') as f:\n",
    "    yaml.dump(data_config, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(\"‚úÖ data.yaml configurado con 8 clases EPP\\n\")\n",
    "print(f\"Clases detectables ({data_config['nc']}):\")\n",
    "for i, name in enumerate(data_config['names']):\n",
    "    print(f\"  {i}: {name}\")\n",
    "\n",
    "print(\"\\nüí° Nota: 'epp_completo' se calcular√° program√°ticamente en el backend\")\n",
    "print(\"   EPP Completo = todas las 8 clases detectadas\")\n",
    "\n",
    "# Verificar contenido\n",
    "print(\"\\nüìÑ Contenido de data.yaml:\")\n",
    "with open('EPP_dataset/data.yaml', 'r') as f:\n",
    "    print(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7Ô∏è‚É£ Entrenar el modelo\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "print(\"üöÄ Iniciando entrenamiento...\\n\")\n",
    "\n",
    "# Detectar dispositivo disponible\n",
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Dispositivo: {'GPU' if device == 0 else 'CPU'}\")\n",
    "\n",
    "if device == 'cpu':\n",
    "    print(\"‚ö†Ô∏è  ADVERTENCIA: Entrenando en CPU (muy lento)\")\n",
    "    print(\"   Recomendaci√≥n: Activa GPU en Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")\n",
    "    input(\"Presiona ENTER para continuar de todos modos...\")\n",
    "\n",
    "# Cargar modelo base\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Entrenar\n",
    "results = model.train(\n",
    "    data='EPP_dataset/data.yaml',\n",
    "    epochs=50,              # 50 √©pocas\n",
    "    imgsz=640,              # Tama√±o de imagen\n",
    "    batch=16 if device == 0 else 4,  # Batch m√°s peque√±o para CPU\n",
    "    device=device,          # Usar GPU si est√° disponible, sino CPU\n",
    "    project='runs/ppe',     # Carpeta de resultados\n",
    "    name='train',           # Nombre del experimento\n",
    "    patience=10,            # Early stopping\n",
    "    save=True,              # Guardar modelo\n",
    "    plots=True,             # Generar gr√°ficas\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8Ô∏è‚É£ Verificar resultados\n",
    "!ls -lh runs/ppe/train/weights/\n",
    "\n",
    "print(\"\\nüìä Modelos generados:\")\n",
    "print(\"  - best.pt: Mejor modelo (menor loss)\")\n",
    "print(\"  - last.pt: √öltimo checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b9edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9Ô∏è‚É£ Ver m√©tricas de entrenamiento\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"üìà Curvas de entrenamiento:\")\n",
    "display(Image('runs/ppe/train/results.png'))\n",
    "\n",
    "print(\"\\nüîç Matriz de confusi√≥n:\")\n",
    "display(Image('runs/ppe/train/confusion_matrix.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d357a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîü Probar el modelo entrenado\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar mejor modelo\n",
    "trained_model = YOLO('runs/ppe/train/weights/best.pt')\n",
    "\n",
    "# Buscar una imagen de prueba\n",
    "import glob\n",
    "test_images = glob.glob('EPP_dataset/train/images/*.jpg')[:3]\n",
    "\n",
    "print(f\"üß™ Probando con {len(test_images)} im√°genes...\\n\")\n",
    "\n",
    "for img_path in test_images:\n",
    "    # Predecir\n",
    "    results = trained_model(img_path)\n",
    "    \n",
    "    # Mostrar\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(results[0].plot())\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Detecciones en {img_path.split('/')[-1]}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar detecciones\n",
    "    if len(results[0].boxes) > 0:\n",
    "        print(f\"  ‚úÖ {len(results[0].boxes)} objeto(s) detectado(s)\")\n",
    "        for box in results[0].boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            name = trained_model.names[cls]\n",
    "            print(f\"     - {name}: {conf:.2%}\")\n",
    "    else:\n",
    "        print(\"  ‚ÑπÔ∏è  No se detectaron objetos\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf16130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£1Ô∏è‚É£ Descargar modelo entrenado\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Copiar y renombrar\n",
    "shutil.copy('runs/ppe/train/weights/best.pt', 'ppe_best.pt')\n",
    "\n",
    "print(\"üì• Descargando modelo entrenado...\")\n",
    "files.download('ppe_best.pt')\n",
    "\n",
    "print(\"\\n‚úÖ Modelo descargado: ppe_best.pt\")\n",
    "print(\"\\nüìù Siguiente paso:\")\n",
    "print(\"  1. Copia ppe_best.pt a: API/models/\")\n",
    "print(\"  2. Configura en .env:\")\n",
    "print(\"     MODEL_PATH=models/ppe_best.pt\")\n",
    "print(\"     USE_ROBOFLOW=False\")\n",
    "print(\"  3. Ejecuta: python main.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99162c90",
   "metadata": {},
   "source": [
    "## üéâ ¬°Entrenamiento Completado!\n",
    "\n",
    "### üìä Resultados\n",
    "- Modelo entrenado: `ppe_best.pt`\n",
    "- Gr√°ficas en: `runs/ppe/train/`\n",
    "\n",
    "### üîÑ Pr√≥ximos Pasos\n",
    "1. Descarga `ppe_best.pt`\n",
    "2. Col√≥calo en `API/models/`\n",
    "3. Actualiza `.env`:\n",
    "   ```\n",
    "   MODEL_PATH=models/ppe_best.pt\n",
    "   USE_ROBOFLOW=False\n",
    "   ```\n",
    "4. Inicia la API: `python main.py`\n",
    "\n",
    "### üîß Si quieres mejorar el modelo\n",
    "- Aumenta `epochs` (ej: 100-200)\n",
    "- Usa modelo m√°s grande: `yolov8s.pt` o `yolov8m.pt`\n",
    "- Ajusta `batch` seg√∫n memoria GPU\n",
    "- Aplica m√°s augmentation\n",
    "\n",
    "### üìù Clases detectadas (8)\n",
    "0. **barbijo** - Mascarilla/Tapabocas\n",
    "1. **botas** - Calzado de seguridad\n",
    "2. **camisa** - Camisa de trabajo\n",
    "3. **casco** - Casco de seguridad\n",
    "4. **chaleco** - Chaleco reflectivo\n",
    "5. **guantes** - Guantes de protecci√≥n\n",
    "6. **lentes** - Gafas de seguridad\n",
    "7. **pantalon** - Pantal√≥n de trabajo\n",
    "\n",
    "**Nota**: `epp_completo` se calcula program√°ticamente cuando se detectan las 8 clases\n",
    "\n",
    "### üí° Tips para mejor precisi√≥n\n",
    "- Usa el dataset augmentado (~14,000 im√°genes)\n",
    "- Entrena por m√°s √©pocas (100+)\n",
    "- Valida con im√°genes reales no vistas\n",
    "- Ajusta threshold de confianza en producci√≥n\n",
    "\n",
    "### ‚≠ê Ventajas del nuevo enfoque\n",
    "- ‚úÖ **M√°s preciso**: 100% en cada clase vs 0% en epp_completo\n",
    "- ‚úÖ **M√°s flexible**: Ajusta qu√© constituye EPP completo sin re-entrenar\n",
    "- ‚úÖ **Mejor UX**: Usuario ve exactamente qu√© piezas faltan\n",
    "- ‚úÖ **M√°s confiable**: Basado en detecciones individuales verificadas\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
